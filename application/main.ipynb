{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 16:20:43.038532: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-20 16:20:43.042583: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-20 16:20:43.110192: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath(\"/projects/renal/srm_detection_main\"))\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import monai\n",
    "from monai.data import pad_list_data_collate\n",
    "\n",
    "from utils import *\n",
    "from constants import *\n",
    "from data.transforms import get_kidney_transforms, get_srm_transforms, InfiniteSampler\n",
    "from data.dataset import ROIDataset\n",
    "from monai.data import pad_list_data_collate\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    LoadImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    ResampleToMatchd,\n",
    "    LabelToContourd,\n",
    "    KeepLargestConnectedComponentd,\n",
    "    FillHolesd,\n",
    "    RandSpatialCropSamplesd,\n",
    "    MapLabelValued,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kidney_transforms(mode=\"holdout\", keys=(\"img\",)):  # Only \"img\" key since you're using images\n",
    "    \"\"\"Get specific transforms for labeled and unlabeled datasets\"\"\"\n",
    "    xforms = [\n",
    "        LoadImaged(keys, allow_missing_keys=True),\n",
    "        EnsureChannelFirstd(keys),\n",
    "        Spacingd(keys[0], pixdim=(2.0, 2.0, 5.0), mode=\"bilinear\"),  # Only apply to \"img\"\n",
    "        ScaleIntensityRanged(keys[0], a_min=-500.0, a_max=500.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "    ]\n",
    "    \n",
    "    # Additional transforms for other modes\n",
    "    if mode == \"unlabeled_train\":\n",
    "        xforms.extend(\n",
    "            [\n",
    "                # These will apply when you have 'seg' and 'pred' in your data dictionary\n",
    "                ResampleToMatchd(keys={\"img\", \"seg\"}, key_dst=\"pred\"),\n",
    "                LabelToContourd(keys={\"pred\"}),\n",
    "                KeepLargestConnectedComponentd(keys={\"pred\"}, is_onehot=False, independent=True, connectivity=3, num_components=2),\n",
    "                FillHolesd(keys={\"pred\"}, applied_labels=[1, 2], connectivity=3),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    return Compose(xforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nrrd\n",
    "import torch\n",
    "import monai\n",
    "\n",
    "def predict_kidneys(image_path, \n",
    "                    vol_dir=\"/projects/renal/demo_predictions/whole/volumes\", \n",
    "                    mask_dir=\"/projects/renal/demo_predictions/whole/masks\"):\n",
    "    \n",
    "    # Load image\n",
    "    train_files = [{\"img\": image_path}]\n",
    "\n",
    "    # Create the transforms for image\n",
    "    labeled_train_transforms = get_kidney_transforms(\"holdout\", keys=(\"img\",))\n",
    "\n",
    "    # Create the CacheDataset and DataLoader\n",
    "    train_ds = monai.data.CacheDataset(data=train_files, transform=labeled_train_transforms)\n",
    "\n",
    "    holdout_whole_loader = monai.data.DataLoader(\n",
    "        train_ds,\n",
    "        num_workers=4,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        batch_size=1,  # Adjust batch size as needed\n",
    "    )\n",
    "\n",
    "    # MT model\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    model = monai.networks.nets.BasicUNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=3,\n",
    "        features=(16, 32, 64, 128, 256, 32),\n",
    "        dropout=0.5,\n",
    "    ).to(device)\n",
    "\n",
    "    ## Load MT Model\n",
    "    state_dict = torch.load(os.path.join(\"/projects/renal/01_kidney_segmentation/semi_supervised/01_mean_teacher/model/best_metric_model_full_256.pth\"), map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():  \n",
    "        for test_data in holdout_whole_loader:  # only one image in dataloader\n",
    "            test_outputs = model(test_data[\"img\"].to(device))\n",
    "            \n",
    "        mask = torch.argmax(test_outputs, dim=1).detach().cpu().squeeze(0)  # remove batch\n",
    "        volume = test_data[\"img\"].to(device).squeeze(0).squeeze(0)\n",
    "\n",
    "    # Convert to numpy arrays for saving\n",
    "    mask_np = mask.numpy()\n",
    "    volume_np = volume.numpy()\n",
    "\n",
    "    # Extract patient name from image_path\n",
    "    patient_name = os.path.basename(os.path.dirname(os.path.dirname(image_path)))\n",
    "\n",
    "    # Define output paths with patient name\n",
    "    mask_path = os.path.join(mask_dir, f\"{patient_name}_output_mask.seg.nrrd\")\n",
    "    volume_path = os.path.join(vol_dir, f\"{patient_name}_output_volume.nrrd\")\n",
    "\n",
    "    # Save the mask and volume\n",
    "    nrrd.write(mask_path, mask_np)\n",
    "    nrrd.write(volume_path, volume_np)\n",
    "\n",
    "    return mask, volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nrrd\n",
    "import os\n",
    "\n",
    "def load_cropped_data(predictions_dir):\n",
    "    cropped_data = {\n",
    "        \"Patient_ID\": [],\n",
    "        \"img\": [],\n",
    "        \"seg\": []\n",
    "    }\n",
    "    \n",
    "    # List all patient directories\n",
    "    patient_dirs = [d for d in os.listdir(predictions_dir) if os.path.isdir(os.path.join(predictions_dir, d))]\n",
    "    \n",
    "    for patient_id in patient_dirs:\n",
    "        patient_dir = os.path.join(predictions_dir, patient_id)\n",
    "        \n",
    "        # Define file paths for image and segmentation\n",
    "        image_filename = os.path.join(patient_dir, f'cropped_image_{patient_id}.nrrd')\n",
    "        seg_filename = os.path.join(patient_dir, f'cropped_image_{patient_id}.seg.nrrd')\n",
    "        \n",
    "        # Read the image and segmentation files\n",
    "        image, _ = nrrd.read(image_filename)\n",
    "        seg, _ = nrrd.read(seg_filename)\n",
    "        \n",
    "        # Append data to the lists in the dictionary\n",
    "        cropped_data[\"Patient_ID\"].append(patient_id)\n",
    "        cropped_data[\"img\"].append(image)\n",
    "        cropped_data[\"seg\"].append(seg)\n",
    "    \n",
    "    return cropped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_cropped_srm(image, patient_id, voi_dir=\"/projects/renal/demo_predictions/cropped/volumes\", mask_dir=\"/projects/renal/demo_predictions/cropped/masks\"):\n",
    "    \n",
    "    test_files = [{\"img\": image}]\n",
    "\n",
    "    test_ds = monai.data.CacheDataset(test_files)\n",
    "\n",
    "    test_loader = monai.data.DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=4,  # image-level batch to the sliding window method\n",
    "        num_workers=4,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        collate_fn=pad_list_data_collate,\n",
    "    )\n",
    "\n",
    "    # MT model\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    model = monai.networks.nets.BasicUNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "        features=(16, 32, 64, 128, 32, 16),\n",
    "        dropout=0.1,\n",
    "    ).to(device)\n",
    "\n",
    "    ## Load MT Model\n",
    "    state_dict = torch.load(os.path.join(\"/projects/renal/srm_detection_main/models/weights_draft/segmentation/srm/best_fully_supervised_srm_model_fold_5.pth\"), map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():  \n",
    "        for test_data in test_loader:  # only one image in dataloader\n",
    "            test_outputs = model(test_data[\"img\"].squeeze(0).to(device))\n",
    "            \n",
    "        mask = torch.argmax(test_outputs, dim=1).detach().cpu().squeeze(0)  # remove batch\n",
    "        volume = test_data[\"img\"].to(device).squeeze(0).squeeze(0).squeeze(0)\n",
    "\n",
    "    # Convert to numpy arrays for saving\n",
    "    mask_np = mask.numpy()\n",
    "    volume_np = volume.numpy()\n",
    "\n",
    "    # Define output paths with patient ID\n",
    "    mask_path = os.path.join(mask_dir, f\"{patient_id}_output_mask.seg.nrrd\")\n",
    "    volume_path = os.path.join(voi_dir, f\"{patient_id}_output_volume.nrrd\")\n",
    "\n",
    "    # Save the mask and volume\n",
    "    nrrd.write(mask_path, mask_np)\n",
    "    nrrd.write(volume_path, volume_np)\n",
    "\n",
    "    return mask, volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import monai\n",
    "\n",
    "def predict_srm(cropped_data, model, output_path, keys, n_samples=50):\n",
    "    \n",
    "    test_files = [{\"img\": img, \"id\": id} for img, id in zip(cropped_data['img'], cropped_data[\"Patient_ID\"])]\n",
    "    test_ds = monai.data.CacheDataset(test_files)\n",
    "    test_loader = monai.data.DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=1,\n",
    "        num_workers=4,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        collate_fn=pad_list_data_collate,\n",
    "    )\n",
    "\n",
    "    # Setup device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the best model\n",
    "    best_cnn_model = PatNET().to(device)\n",
    "    best_cnn_model.load_state_dict(torch.load(model, map_location=torch.device('cpu')))\n",
    "    \n",
    "    # Ensure dropout remains active during inference\n",
    "    best_cnn_model.train()  # Enable dropout\n",
    "    \n",
    "    # Initialize lists to store probabilities, predictions, and patient IDs\n",
    "    all_probabilities = []\n",
    "    patient_ids = []\n",
    "    predictions = []\n",
    "    predicted_probs = []\n",
    "    std_probs = []  # To store standard deviations\n",
    "\n",
    "    # Disable gradient calculation for inference\n",
    "    with torch.no_grad():\n",
    "        for test_data in test_loader:\n",
    "            input_tensor = test_data[\"img\"].squeeze(0).clone().detach().to(device)\n",
    "            patient_id = test_data[\"id\"][0]  # Extract patient ID (since batch size = 1)\n",
    "\n",
    "            # Collect multiple predictions with dropout enabled\n",
    "            probabilities = []\n",
    "            for _ in range(n_samples):\n",
    "                output, _ = best_cnn_model(input_tensor)  # Forward pass\n",
    "                prob = torch.softmax(output, dim=1).cpu().numpy()\n",
    "                probabilities.append(prob)\n",
    "            \n",
    "            probabilities = np.array(probabilities)\n",
    "            mean_prob = probabilities.mean(axis=0)  # Mean probability over all samples\n",
    "            std_prob = probabilities.std(axis=0)    # Standard deviation of the probabilities\n",
    "\n",
    "            all_probabilities.append(mean_prob)\n",
    "            std_probs.append(std_prob)\n",
    "            patient_ids.append(patient_id)\n",
    "\n",
    "            # Determine the predicted class and its probability\n",
    "            if mean_prob[0, 0] > mean_prob[0, 1]:\n",
    "                predictions.append(keys[0])\n",
    "                predicted_probs.append(mean_prob[0, 0])\n",
    "            else:\n",
    "                predictions.append(keys[1])\n",
    "                predicted_probs.append(mean_prob[0, 1])\n",
    "\n",
    "    # Convert list of arrays to a numpy array for bootstrapping\n",
    "    all_probabilities = np.array(all_probabilities)\n",
    "\n",
    "    # Create a DataFrame with Patient_ID, Prediction, Probability, and Standard Deviation\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Patient_ID\": patient_ids,\n",
    "        \"Prediction\": predictions,\n",
    "        \"Probability\": predicted_probs,\n",
    "        \"Std_Prob\": [std[0, 1] if pred == keys[1] else std[0, 0] for pred, std in zip(predictions, std_probs)]\n",
    "    })\n",
    "\n",
    "    # Save DataFrame to CSV\n",
    "    results_df.to_csv(f\"{output_path}\", index=False)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference for Kidney Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (16, 32, 64, 128, 256, 32).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_path = '/projects/renal/srm_detection_main/application/holdout/whole/Renal-CHUS-0107/CECT/CECT.nrrd'\n",
    "mask, volume = predict_kidneys(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8d8e977ee0>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(\"check\", (18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(mask[:, :, 10], cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference for SRM Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 11/11 [00:00<00:00, 1023.84it/s]\n"
     ]
    }
   ],
   "source": [
    "cropped_image_path = \"/projects/renal/srm_detection_main/application/holdout/voi\"\n",
    "cropped_data = load_cropped_data(cropped_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00, 876.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (16, 32, 64, 128, 32, 16).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00, 2807.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (16, 32, 64, 128, 32, 16).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00, 2998.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (16, 32, 64, 128, 32, 16).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00, 10782.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (16, 32, 64, 128, 32, 16).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00, 9799.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (16, 32, 64, 128, 32, 16).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00, 3741.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (16, 32, 64, 128, 32, 16).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00, 1845.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (16, 32, 64, 128, 32, 16).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (16, 32, 64, 128, 32, 16).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00, 12595.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (16, 32, 64, 128, 32, 16).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00, 1582.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (16, 32, 64, 128, 32, 16).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00, 9962.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (16, 32, 64, 128, 32, 16).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    voi_mask, voi = predict_cropped_srm(cropped_data['img'][i], cropped_data['Patient_ID'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8d929ef6d0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(\"check\", (18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(voi[:, :, 10], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Dropout: \n",
    "\n",
    "- We enabled dropout by setting best_cnn_model.train(), even during inference.\n",
    "\n",
    "- Multiple Predictions: For each sample, the model runs n_samples times to generate multiple probabilities, which are then averaged to get the mean probability and standard deviation.\n",
    "\n",
    "- Standard Deviation: The standard deviation of the probabilities is calculated to represent the model's uncertainty for each sample.\n",
    "This approach gives us both the predicted class and its associated confidence level (mean probability and standard deviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 11/11 [00:00<00:00, 1210.38it/s]\n",
      "Loading dataset: 100%|██████████| 11/11 [00:00<00:00, 1374.12it/s]\n",
      "Loading dataset: 100%|██████████| 11/11 [00:00<00:00, 1618.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Std_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Renal-CHUS-0062</td>\n",
       "      <td>ccRCC</td>\n",
       "      <td>0.999018</td>\n",
       "      <td>0.002906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Renal-CHUS-0050</td>\n",
       "      <td>papRCC</td>\n",
       "      <td>0.806733</td>\n",
       "      <td>0.125563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Renal-CHUS-0073</td>\n",
       "      <td>ccRCC</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.000534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Renal-CHUS-0105</td>\n",
       "      <td>ccRCC</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Renal-CHUS-0107</td>\n",
       "      <td>ccRCC</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Renal-CHUS-0061</td>\n",
       "      <td>ccRCC</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Renal-CHUS-0106</td>\n",
       "      <td>ccRCC</td>\n",
       "      <td>0.971639</td>\n",
       "      <td>0.050814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Renal-CHUS-0048</td>\n",
       "      <td>ccRCC</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Renal-CHUS-0069</td>\n",
       "      <td>papRCC</td>\n",
       "      <td>0.560147</td>\n",
       "      <td>0.045017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Renal-CHUS-0068</td>\n",
       "      <td>ccRCC</td>\n",
       "      <td>0.946213</td>\n",
       "      <td>0.094350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Renal-CHUS-0074</td>\n",
       "      <td>ccRCC</td>\n",
       "      <td>0.997151</td>\n",
       "      <td>0.003214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Patient_ID Prediction  Probability  Std_Prob\n",
       "0   Renal-CHUS-0062      ccRCC     0.999018  0.002906\n",
       "1   Renal-CHUS-0050     papRCC     0.806733  0.125563\n",
       "2   Renal-CHUS-0073      ccRCC     0.999874  0.000534\n",
       "3   Renal-CHUS-0105      ccRCC     0.999997  0.000012\n",
       "4   Renal-CHUS-0107      ccRCC     0.999988  0.000042\n",
       "5   Renal-CHUS-0061      ccRCC     0.999940  0.000358\n",
       "6   Renal-CHUS-0106      ccRCC     0.971639  0.050814\n",
       "7   Renal-CHUS-0048      ccRCC     0.999708  0.000468\n",
       "8   Renal-CHUS-0069     papRCC     0.560147  0.045017\n",
       "9   Renal-CHUS-0068      ccRCC     0.946213  0.094350\n",
       "10  Renal-CHUS-0074      ccRCC     0.997151  0.003214"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cc='/projects/renal/srm_detection_main/models/weights/classification/ccRCC_vs_non_ccRCC/best_ccRCC_vs_non_ccRCC_clf_fold_5.pth' \n",
    "output_path_cc=\"/projects/renal/demo_predictions/classification/ccRCC_vs_NonccRCC.csv\"\n",
    "\n",
    "model_grade='/projects/renal/srm_detection_main/models/weights/classification/grade/best_grade_clf_fold_5.pth' \n",
    "output_path_grade=\"/projects/renal/demo_predictions/classification/high_vs_low_grade.csv\"\n",
    "\n",
    "model_subtype='/projects/renal/srm_detection_main/models/weights/classification/subtype/best_subtype_clf_fold_5.pth' \n",
    "output_path_subtype=\"/projects/renal/demo_predictions/classification/ccRCC_vs_papRCC.csv\"\n",
    "\n",
    "predict_srm(cropped_data, model_cc, output_path_cc, keys=(\"Non ccRCC\", \"ccRCC\"))\n",
    "predict_srm(cropped_data, model_grade, output_path_grade, keys=(\"Low\", \"High\"))\n",
    "predict_srm(cropped_data, model_subtype, output_path_subtype, keys=(\"papRCC\", \"ccRCC\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
