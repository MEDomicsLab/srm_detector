{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "attempted relative import beyond top-level package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# dependencies for kMT and srmUNet Training\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataloaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_segmentation_data, load_image_data, load_radiomics_data\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SRMDataset\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msegmentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msemi_supervised\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kidney_segmentor, srm_segmentor\n",
      "File \u001b[1;32md:\\srm_detection_pipeline\\srm_detection\\data\\dataloaders.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmonai\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmonai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_list_data_collate\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_kidney_transforms, get_srm_transforms, InfiniteSampler\n",
      "File \u001b[1;32md:\\srm_detection_pipeline\\srm_detection\\utils.py:35\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resample\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SRMDataset, CNNDataset, ROIDataset\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bounding_box, crop\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_srm_transforms, InfiniteSampler\n",
      "File \u001b[1;32md:\\srm_detection_pipeline\\srm_detection\\data\\dataset.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmonai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmt\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m label, find_objects\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_features\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mROIDataset\u001b[39;00m(Dataset):\n\u001b[0;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    Return cropped dataset for segmentation task as one batch with patient ID, image and seg.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import beyond top-level package"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath(os.path.join('..', '..')))\n",
    "\n",
    "# dependencies for kMT and srmUNet Training\n",
    "from data.dataloaders import load_segmentation_data, load_image_data, load_radiomics_data\n",
    "from data.dataset import SRMDataset\n",
    "from models.segmentation.semi_supervised import kidney_segmentor, srm_segmentor\n",
    "from models.classification.classifier import cnn_classifier, xgboost_classifier\n",
    "from models.classification.cnn import PatNET\n",
    "#from utils import save_figures_and_show\n",
    "from evaluation.classification.evaluate import bootstrap_ci, get_xgb_predictions\n",
    "\n",
    "# dependencies for bounding box coordinates\n",
    "from utils import *\n",
    "from data.roi import load_inference_data, load_labeled_data, load_bbox \n",
    "from data.transforms import get_bbox_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import monai.transforms as mt\n",
    "from scipy.ndimage import label, find_objects\n",
    "class InferDataset(Dataset):\n",
    "    \"\"\"\n",
    "     Used in the function \"pos_neg_aug_datasets\" to generate a positive/negative dataset \n",
    "     that will be used to control the original batch and augmented batch independently.\n",
    "     It returns batches with patient ID, image, seg, label.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, data_rcc, q3_x_len=30, q3_y_len=61, q3_z_len=45, transform=None, augment_neg=False, augment_pos=False, aug_pos_rate=None, aug_neg_rate=None):\n",
    "        self.data = data  # csv file that has patient id, image, seg, pred paths and bbox coords\n",
    "        self.data_rcc = data_rcc\n",
    "        self.q3_x_len = q3_x_len\n",
    "        self.q3_y_len = q3_y_len\n",
    "        self.q3_z_len = q3_z_len\n",
    "        self.transform = transform\n",
    "        self.augment_neg = augment_neg\n",
    "        self.augment_pos = augment_pos\n",
    "        self.aug_pos_rate = aug_pos_rate\n",
    "        self.aug_neg_rate = aug_neg_rate\n",
    "\n",
    "    def __len__(self):\n",
    "        if \"root\" in self.data.keys():\n",
    "            return len(self.data['root'])  # change to: data.keys()[0]\n",
    "        else: \n",
    "            return len(self.data['img'])\n",
    "\n",
    "    def get_box_centers(self, box):\n",
    "        x_start, y_start, z_start, x_len, y_len, z_len = box\n",
    "        x_center = x_start + x_len // 2\n",
    "        y_center = y_start + y_len // 2 \n",
    "        z_center = z_start + z_len // 2 \n",
    "        return x_center, y_center, z_center\n",
    "\n",
    "    def crop(self, resized_img, resized_seg, pred, box):\n",
    "        \n",
    "        x_start, y_start, z_start, x_len, y_len, z_len = box \n",
    "\n",
    "        x_center = x_start+x_len//2\n",
    "        y_center = y_start+y_len//2\n",
    "        z_center = z_start+z_len//2\n",
    "\n",
    "        roi_center = (z_center, y_center, x_center)\n",
    "        roi_size = (z_len,y_len,x_len)\n",
    "\n",
    "            \n",
    "        # Crop the image, seg and prediction to match box area\n",
    "        cropper = mt.SpatialCrop(roi_center=roi_center, roi_size=roi_size)\n",
    "        \n",
    "        \n",
    "        crop_pred = cropper(pred)\n",
    "        crop_img = cropper(resized_img)\n",
    "        crop_seg = cropper(resized_seg)\n",
    "        crop_depth = crop_pred.shape[3]\n",
    "\n",
    "        return crop_img, crop_seg, crop_pred, crop_depth\n",
    "\n",
    "\n",
    "    def load_resized_data(self, data, i):\n",
    "\n",
    "        # Load image, segmentation, prediction and boxes from data.csvseg_path = data[\"seg\"][i]\n",
    "        img_path = data['img'][i]\n",
    "        seg_path = data['pred'][i]\n",
    "        img_proc = mt.Compose([\n",
    "                mt.LoadImage(image_only=True, ensure_channel_first=True),\n",
    "                mt.EnsureType(), \n",
    "                mt.Orientation(axcodes='LPS'),\n",
    "                mt.Spacing(pixdim=(2.0, 2.0, 5.0), mode=(\"nearest\")), \n",
    "                mt.ScaleIntensityRange(a_min=-500.0, a_max=500.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "                mt.ToTensor()\n",
    "                ])\n",
    "        \n",
    "        seg_proc = mt.Compose([\n",
    "                mt.LoadImage(image_only=True, ensure_channel_first=True),\n",
    "                mt.EnsureType(), \n",
    "                mt.Orientation(axcodes='LPS'),\n",
    "                mt.Spacing(pixdim=(2.0, 2.0, 5.0), mode=(\"bilinear\")), \n",
    "                mt.ScaleIntensityRange(a_min=-500.0, a_max=500.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "                mt.ToTensor()\n",
    "                ])\n",
    "        \n",
    "        seg = seg_proc(seg_path)\n",
    "        img = img_proc(img_path)\n",
    "\n",
    "        # sitk : D H W    monai : W H D\n",
    "        x = seg.shape[1]\n",
    "        y = seg.shape[2]\n",
    "        z = seg.shape[3]\n",
    "\n",
    "        # Resize image and segmentation so they match prediction in shape\n",
    "        resize_transform = mt.Resize(spatial_size=(x, y, z))\n",
    "        resized_img = resize_transform(img)\n",
    "        resized_seg = resize_transform(seg)\n",
    "\n",
    "        return resized_img, resized_seg\n",
    "    \n",
    "    def resize_before_train(self, img, seg):\n",
    "\n",
    "\n",
    "        resize_transform = mt.Resize(spatial_size=(64, 64, 32))\n",
    "        resized_img = resize_transform(img)\n",
    "        resized_seg = resize_transform(seg)\n",
    "        \n",
    "\n",
    "        return resized_img, resized_seg\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    def checker(self, crop_seg):\n",
    "        \"\"\"\n",
    "        Check if the crop_seg contains a tumor.\n",
    "        \n",
    "        Parameters:\n",
    "        crop_seg (numpy array): The cropped segmentation mask.\n",
    "        box (tuple): The bounding box coordinates (x, y, z, x_len, y_len, z_len).\n",
    "        \n",
    "        Returns:\n",
    "        int: 1 if the crop_seg contains a tumor, 0 otherwise.\n",
    "        \"\"\"\n",
    "        # Tumor label is 1\n",
    "        \n",
    "        tumor_label = 0.5\n",
    "        return 1 if np.any(crop_seg > tumor_label) else 0\n",
    "        \n",
    "\n",
    "    def retrieve_kidney_boxes(self, boxes):\n",
    "        \n",
    "        kidney_boxes = []\n",
    "        for box in boxes:\n",
    "            x_start, y_start, z_start, x_len, y_len, z_len = box \n",
    "            volume = x_len * y_len * z_len\n",
    "            kidney_boxes.append((x_start, y_start, z_start, x_len, y_len, z_len, volume))\n",
    "        kidney_boxes = sorted(kidney_boxes, key=lambda x: x[6], reverse=True)[:2]\n",
    "        kidney_boxes = [(x_start, y_start, z_start, x_len, y_len, z_len) for x_start, y_start, z_start, x_len, y_len, z_len, _ in kidney_boxes]\n",
    "        return kidney_boxes\n",
    "    \n",
    "    # Function to calculate bounding boxes from binary masks\n",
    "    def bounding_box(self, mask):\n",
    "        mask_np = mask.squeeze().cpu().numpy()  # Convert tensor to numpy array\n",
    "        labeled, num_features = label(mask_np)  # Label connected components\n",
    "        objects = find_objects(labeled)  # Find bounding boxes for each connected component\n",
    "\n",
    "        boxes = []\n",
    "        for obj in objects:\n",
    "            z_start, z_end = obj[0].start, obj[0].stop\n",
    "            y_start, y_end = obj[1].start, obj[1].stop\n",
    "            x_start, x_end = obj[2].start, obj[2].stop\n",
    "            x_len = x_end - x_start\n",
    "            y_len = y_end - y_start\n",
    "            z_len = z_end - z_start\n",
    "            volume = x_len * y_len * z_len\n",
    "            boxes.append((x_start, y_start, z_start, x_len, y_len, z_len, volume))\n",
    "        \n",
    "        # Sort boxes by volume in descending order and take the two largest\n",
    "        boxes = sorted(boxes, key=lambda x: x[6], reverse=True)[:2]\n",
    "        \n",
    "        # Remove the volume information from the output\n",
    "        boxes = [(x_start, y_start, z_start, x_len, y_len, z_len) for x_start, y_start, z_start, x_len, y_len, z_len, _ in boxes]\n",
    "        \n",
    "        return boxes\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        patient_id = self.data['root'][idx]\n",
    "\n",
    "        target = self.data_rcc[idx]\n",
    "        resized_img, resized_seg, pred = self.load_resized_data(self.data, idx)\n",
    "        kidney_boxes = self.bounding_box(pred)\n",
    "\n",
    "        r_box= kidney_boxes[0]\n",
    "        l_box= kidney_boxes[1]\n",
    "\n",
    "        l_crop_img, l_crop_seg, l_crop_pred, _ = self.crop(resized_img, resized_seg, pred, l_box)\n",
    "        r_crop_img, r_crop_seg, r_crop_pred, _ = self.crop(resized_img, resized_seg, pred, r_box)\n",
    "                            \n",
    "\n",
    "        # select the kidney image and segment that contain tumor, ignore the other\n",
    "        if self.checker(r_crop_seg) == 1:  # right contains tumor\n",
    "            if self.transform:\n",
    "                r_crop_img = self.transform(r_crop_img)\n",
    "                r_crop_seg = self.transform(r_crop_seg)\n",
    "\n",
    "            img, seg = self.resize_before_train(r_crop_img, r_crop_seg)\n",
    "        \n",
    "\n",
    "        else: # self.checker(l_crop_seg) == 1:  # left contains tumor\n",
    "                if self.transform:\n",
    "                    l_crop_img = self.transform(l_crop_img)\n",
    "                    l_crop_seg = self.transform(l_crop_seg)\n",
    "            \n",
    "                img, seg = self.resize_before_train(l_crop_img, l_crop_seg)\n",
    "\n",
    "    \n",
    "\n",
    "        batch = {\n",
    "            'Patient_ID': patient_id,\n",
    "            'img': img,\n",
    "            'pred': seg,\n",
    "            'label': torch.tensor(target, dtype=torch.long)  # Target is a single label\n",
    "        }\n",
    "\n",
    "\n",
    "        return batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Labeled Patients: 100%|██████████| 1/1 [00:00<00:00, 917.79it/s]\n",
      "Loading boxes: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dictionary saved as D:\\\\srm_detection_pipeline\\\\application\\\\dataset\\\\bbox.csv.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data  = load_inference_data(\"D:\\\\srm_detection_pipeline\\\\application\\\\dataset\\\\holdout\\\\whole\")\n",
    "test_dataset = SRMDataset(data=test_data, data_rcc=pd.read_csv(\"D:\\\\srm_detection_pipeline\\\\application\\\\dataset\\\\labels.csv\")['labels'].tolist()) \n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "# returns dict with img, patient id, label and radiomics\n",
    "post_proc_transform, post_pred_transform = get_bbox_transforms()\n",
    "csv_data = load_bbox(test_data, post_pred_transform) \n",
    "save_dict_as_csv(csv_data, \"D:\\\\srm_detection_pipeline\\\\application\\\\dataset\\\\bbox.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msave_gifs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_proc_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_pred_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43msrm_detection_pipeline\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mapplication\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabeled\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\srm_detection_pipeline\\srm_detection\\utils.py:1260\u001b[0m, in \u001b[0;36msave_gifs\u001b[1;34m(data, post_proc, post_pred, output_folder, tag)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_gifs\u001b[39m(data, post_proc, post_pred, output_folder\u001b[38;5;241m=\u001b[39mGIFS_FOLDER, tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m'\u001b[39m])):  \u001b[38;5;66;03m#len(data)\u001b[39;00m\n\u001b[0;32m   1258\u001b[0m         \u001b[38;5;66;03m# Generate a random integer i from 0 to 250\u001b[39;00m\n\u001b[1;32m-> 1260\u001b[0m         img_sample \u001b[38;5;241m=\u001b[39m \u001b[43mpost_proc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseg\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1262\u001b[0m             mask_sample \u001b[38;5;241m=\u001b[39m post_pred(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseg\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\monai\\transforms\\compose.py:335\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, input_, start, end, threading, lazy)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, threading\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, lazy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    334\u001b[0m     _lazy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy \u001b[38;5;28;01mif\u001b[39;00m lazy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lazy\n\u001b[1;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_compose\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_lazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreading\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreading\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\monai\\transforms\\compose.py:111\u001b[0m, in \u001b[0;36mexecute_compose\u001b[1;34m(data, transforms, map_items, unpack_items, start, end, lazy, overrides, threading, log_stats)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threading:\n\u001b[0;32m    110\u001b[0m         _transform \u001b[38;5;241m=\u001b[39m deepcopy(_transform) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_transform, ThreadUnsafe) \u001b[38;5;28;01melse\u001b[39;00m _transform\n\u001b[1;32m--> 111\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_stats\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m data \u001b[38;5;241m=\u001b[39m apply_pending_transforms(data, \u001b[38;5;28;01mNone\u001b[39;00m, overrides, logger_name\u001b[38;5;241m=\u001b[39mlog_stats)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\monai\\transforms\\transform.py:141\u001b[0m, in \u001b[0;36mapply_transform\u001b[1;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m map_items:\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items, lazy, overrides, log_stats) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# if in debug mode, don't swallow exception so that the breakpoint\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# appears where the exception was raised.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m MONAIEnvVars\u001b[38;5;241m.\u001b[39mdebug():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\monai\\transforms\\transform.py:98\u001b[0m, in \u001b[0;36m_apply_transform\u001b[1;34m(transform, data, unpack_parameters, lazy, overrides, logger_name)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m unpack_parameters:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transform(data, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\monai\\transforms\\io\\array.py:292\u001b[0m, in \u001b[0;36mLoadImage.__call__\u001b[1;34m(self, filename, reader)\u001b[0m\n\u001b[0;32m    290\u001b[0m img_array: NdarrayOrTensor\n\u001b[0;32m    291\u001b[0m img_array, meta_data \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mget_data(img)\n\u001b[1;32m--> 292\u001b[0m img_array \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_dst_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(meta_data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`meta_data` must be a dict, got type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(meta_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\monai\\utils\\type_conversion.py:388\u001b[0m, in \u001b[0;36mconvert_to_dst_type\u001b[1;34m(src, dst, dtype, wrap_sequence, device, safe)\u001b[0m\n\u001b[0;32m    386\u001b[0m     output_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(dst)\n\u001b[0;32m    387\u001b[0m output: NdarrayTensor\n\u001b[1;32m--> 388\u001b[0m output, _type, _device \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_data_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrap_sequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrap_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, monai\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mMetaTensor):\n\u001b[0;32m    392\u001b[0m     output\u001b[38;5;241m.\u001b[39mcopy_meta_from(dst)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\monai\\utils\\type_conversion.py:335\u001b[0m, in \u001b[0;36mconvert_data_type\u001b[1;34m(data, output_type, device, dtype, wrap_sequence, safe)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_, orig_type, orig_device\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(output_type, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m--> 335\u001b[0m     data_ \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrap_sequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrap_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_, orig_type, orig_device\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m has_cp \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(output_type, cp\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\monai\\utils\\type_conversion.py:224\u001b[0m, in \u001b[0;36mconvert_to_numpy\u001b[1;34m(data, dtype, wrap_sequence, safe)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: convert_to_numpy(v, dtype\u001b[38;5;241m=\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mascontiguousarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_gifs(test_data, post_proc_transform, post_pred_transform, output_folder=\"D:\\\\srm_detection_pipeline\\\\application\\\\dataset\", tag='labeled')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Patients ...:   0%|          | 0/1 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'extract_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m     data_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mradiomics\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features_lesion_list\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_dict\n\u001b[1;32m---> 37\u001b[0m radiomics_dict \u001b[38;5;241m=\u001b[39m \u001b[43mget_clf_data_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m, in \u001b[0;36mget_clf_data_dict\u001b[1;34m(data_loader)\u001b[0m\n\u001b[0;32m     11\u001b[0m bbox_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m features_lesion_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 14\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessing Patients ...\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbboxes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPatient_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbbox\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpatient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbboxes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\srm_detection_pipeline\\srm_detection\\data\\dataset.py:462\u001b[0m, in \u001b[0;36mSRMDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    450\u001b[0m             l_crop_seg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(l_crop_seg)\n\u001b[0;32m    452\u001b[0m         img, seg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize_before_train(l_crop_img, l_crop_seg)\n\u001b[0;32m    456\u001b[0m batch \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m'\u001b[39m: patient_id,\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m: img,\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseg\u001b[39m\u001b[38;5;124m'\u001b[39m: seg,\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m: pred,\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounding_box(pred),\n\u001b[1;32m--> 462\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mradiomics\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mextract_features\u001b[49m(img),\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(target, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)  \u001b[38;5;66;03m# Target is a single label\u001b[39;00m\n\u001b[0;32m    464\u001b[0m }\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment_neg: \n\u001b[0;32m    467\u001b[0m     aug_img, aug_seg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugmenter(img, seg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maug_neg_rate)  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_features' is not defined"
     ]
    }
   ],
   "source": [
    "def get_clf_data_dict(data_loader):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns a dictionary with image tensor, patiend ID, label and radiomics\n",
    "\n",
    "    \"\"\"\n",
    "    root_list = []\n",
    "    img_list = []\n",
    "    seg_list = []\n",
    "    pred_list = []\n",
    "    bbox_list = []\n",
    "    features_lesion_list = []\n",
    "\n",
    "    for data in tqdm(data_loader, desc=\"Processing Patients ...\"):\n",
    "        \n",
    "        root, images, segs, preds, bboxes = data['Patient_ID'], data['img'], data['seg'], data['pred'], data['bbox']\n",
    "        for patient, img, sg, prd, bx in tqdm(zip(root, images, segs, preds, bboxes)):\n",
    "            root_list.append(patient)\n",
    "            img_list.append(img)\n",
    "            seg_list.append(sg)\n",
    "            pred_list.append(prd)\n",
    "            bbox_list.append(bx)\n",
    "            hist_lesion_img = extract_features(img)\n",
    "            features_lesion_list.append(hist_lesion_img)\n",
    "            \n",
    "    \n",
    "    data_dict = dict()\n",
    "    data_dict[\"root\"] = root_list\n",
    "    data_dict[\"img\"] = img_list\n",
    "    data_dict[\"seg\"] = seg_list\n",
    "    data_dict[\"pred\"] = pred_list\n",
    "    data_dict[\"bbox\"] = bbox_list\n",
    "    data_dict[\"radiomics\"] = features_lesion_list\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "radiomics_dict = get_clf_data_dict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['root', 'img', 'seg', 'pred', 'bbox', 'radiomics'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['root', 'img', 'seg', 'pred', 'bbox', 'radiomics'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radiomics_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m X_test_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m y_test_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Convert PyTorch tensor to NumPy\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Convert labels to NumPy\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\srm_detection_pipeline\\srm_detection\\data\\dataset.py:462\u001b[0m, in \u001b[0;36mSRMDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    450\u001b[0m             l_crop_seg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(l_crop_seg)\n\u001b[0;32m    452\u001b[0m         img, seg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize_before_train(l_crop_img, l_crop_seg)\n\u001b[0;32m    456\u001b[0m batch \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m'\u001b[39m: patient_id,\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m: img,\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseg\u001b[39m\u001b[38;5;124m'\u001b[39m: seg,\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m: pred,\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounding_box(pred),\n\u001b[1;32m--> 462\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mradiomics\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mextract_features\u001b[49m(img),\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(target, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)  \u001b[38;5;66;03m# Target is a single label\u001b[39;00m\n\u001b[0;32m    464\u001b[0m }\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment_neg: \n\u001b[0;32m    467\u001b[0m     aug_img, aug_seg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugmenter(img, seg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maug_neg_rate)  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_features' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Extract test data from PyTorch DataLoader\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    imgs = batch[\"img\"].numpy()  # Convert PyTorch tensor to NumPy\n",
    "    labels = batch[\"label\"].numpy()  # Convert labels to NumPy\n",
    "    X_test_list.append(imgs)\n",
    "    y_test_list.append(labels)\n",
    "\n",
    "# Concatenate all batches into a single array\n",
    "X_test_xgb = np.concatenate(X_test_list, axis=0)\n",
    "y_test_xgb = np.concatenate(y_test_list, axis=0)\n",
    "\n",
    "print(\"X_test_xgb shape:\", X_test_xgb.shape)\n",
    "print(\"y_test_xgb shape:\", y_test_xgb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten images if necessary\n",
    "X_test_xgb = X_test_xgb.reshape(X_test_xgb.shape[0], -1)  # Convert to (num_samples, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model_file = \"D:\\\\srm_detection_pipeline\\\\srm_detection\\\\models\\\\weights\\\\classification\\\\ccRCC_vs_non_ccRCC\\\\xgboost\\\\xgboost_model_attempt_9_more_aug_600.bin\"\n",
    "best_xgb_model = xgb.XGBClassifier()\n",
    "best_xgb_model.load_model(xgb_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_xgb_predictions, bootstrap_ci, evaluate_model\n\u001b[1;32m----> 4\u001b[0m xgb_probs \u001b[38;5;241m=\u001b[39m get_xgb_predictions(best_xgb_model, \u001b[43mX_test_xgb\u001b[49m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Perform Stratified K-Fold validation\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StratifiedKFold\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test_xgb' is not defined"
     ]
    }
   ],
   "source": [
    "from evaluation.classification.evaluate import get_xgb_predictions, bootstrap_ci, evaluate_model\n",
    "\n",
    "\n",
    "xgb_probs = get_xgb_predictions(best_xgb_model, X_test_xgb)\n",
    "\n",
    "# Perform Stratified K-Fold validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "test_results = []\n",
    "\n",
    "roc_aucs, sensitivities, specificities = [], [], []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X_test_xgb, y_test_xgb)):\n",
    "    X_true = X_test_xgb[test_index]\n",
    "    y_true = y_test_xgb[test_index]\n",
    "    \n",
    "    y_probs = get_xgb_predictions(best_xgb_model, X_true)\n",
    "    y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "    metrics_report = evaluate_model(y_true, y_preds, y_probs)\n",
    "    \n",
    "    roc_aucs.append(metrics_report['ROC AUC'])\n",
    "    sensitivities.append(metrics_report['Sensitivity'])\n",
    "    specificities.append(metrics_report['Specificity'])\n",
    "\n",
    "    test_results.append({\n",
    "        'Fold': fold + 1,\n",
    "        'ROC AUC': metrics_report['ROC AUC'],\n",
    "        'Sensitivity': metrics_report['Sensitivity'],\n",
    "        'Specificity': metrics_report['Specificity']\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df_results = pd.DataFrame(test_results)\n",
    "print(\"Per-Fold Results:\")\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf.load_model(args.model_path)'''\n",
    "#xgb_probs = get_xgb_predictions(xgb_clf, X_test_xgb)\n",
    "\n",
    "xgb_model_file = f'./models/weights/classification/grade/xgboost/xgboost_model_attempt_8.bin'\n",
    "best_xgb_model = xgb.XGBClassifier()\n",
    "best_xgb_model.load_model(xgb_model_file)\n",
    "\n",
    "xgb_probs = get_xgb_predictions(best_xgb_model, X_test_xgb)\n",
    "# Stratified K-Fold on the test set\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "test_results = []\n",
    "\n",
    "roc_aucs = []\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X_test_xgb, y_test_xgb)):\n",
    "    X_true = np.array([X_test_xgb[i] for i in test_index])\n",
    "    y_true = np.array([y_test_xgb[i] for i in test_index])\n",
    "    y_probs = get_xgb_predictions(best_xgb_model, X_true)\n",
    "    y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "    metrics_report = evaluate_model(y_true, y_preds, y_probs)\n",
    "    roc_aucs.append(metrics_report['ROC AUC'])\n",
    "    sensitivities.append(metrics_report['Sensitivity'])\n",
    "    specificities.append(metrics_report['Specificity'])\n",
    "    \n",
    "    # Append results to the list\n",
    "    test_results.append({\n",
    "        'Fold': fold + 1,\n",
    "        'ROC AUC': metrics_report['ROC AUC'],\n",
    "        'Sensitivity': metrics_report['Sensitivity'],\n",
    "        'Specificity': metrics_report['Specificity']\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "df_results = pd.DataFrame(test_results)\n",
    "\n",
    "# Calculate bootstrap confidence intervals\n",
    "roc_auc_ci_L, roc_auc_ci_U = bootstrap_ci(roc_aucs)\n",
    "sensitivity_ci_L, sensitivity_ci_U = bootstrap_ci(sensitivities)\n",
    "specificity_ci_L, specificity_ci_U  = bootstrap_ci(specificities)\n",
    "\n",
    "# Display the per-fold results\n",
    "print(\"Per-Fold Results:\")\n",
    "print(df_results)\n",
    "\n",
    "# Calculate and display the summary statistics\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Metric': ['ROC AUC', 'Sensitivity', 'Specificity'],\n",
    "    'Mean ± Std': [\n",
    "        f\"{np.mean(roc_aucs):.3f} ± {np.std(roc_aucs):.3f}\",\n",
    "        f\"{np.mean(sensitivities):.3f} ± {np.std(sensitivities):.3f}\",\n",
    "        f\"{np.mean(specificities):.3f} ± {np.std(specificities):.3f}\"\n",
    "    ],\n",
    "    '95% CI': [\n",
    "        f\"{roc_auc_ci_L:.3f} - {roc_auc_ci_U:.3f}\",\n",
    "        f\"{sensitivity_ci_L:.3f} - {sensitivity_ci_U:.3f}\",\n",
    "        f\"{specificity_ci_L:.3f} - {specificity_ci_U:.3f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf.load_model(args.model_path)\n",
    "xgb_probs = get_xgb_predictions(xgb_clf, X_test_xgb)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
